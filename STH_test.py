#!/usr/bin/env python3
"""
STHæ¨¡å‹æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯æ—¶ç©ºæ··åˆæ³¨æ„åŠ›ç½‘ç»œå’Œåˆ†å±‚PPOç®—æ³•çš„å„ä¸ªç»„ä»¶
"""

import numpy as np
import torch
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from STH_model import STHANModel
from STH_ppo import HierarchicalPPO
from STH_utils import (
    HistoryBuffer, create_adjacency_matrix, get_neighbor_obs,
    process_features, reward_shaping, compute_traffic_metrics
)
from STH_config import get_config

def test_model_forward():
    """æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­"""
    print("Testing model forward pass...")
    
    config = get_config('small')
    
    # åˆ›å»ºæ¨¡å‹
    model = STHANModel(
        obs_dim=config['obs_dim'],
        action_dim=config['action_dim'],
        num_agents=config['num_agents'],
        history_len=config['history_len'],
        embed_dim=config['embed_dim'],
        n_heads=config['n_heads']
    )
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 2
    obs = torch.randn(batch_size, config['num_agents'], config['obs_dim'])
    neighbor_obs = torch.randn(batch_size, config['num_agents'], config['num_neighbors'], config['obs_dim'])
    history_obs = torch.randn(batch_size, config['num_agents'], config['history_len'], config['obs_dim'])
    
    # å‰å‘ä¼ æ’­
    high_level_logits, low_level_logits, value, spatial_attn, temporal_attn = model(
        obs, neighbor_obs, history_obs
    )
    
    # æ£€æŸ¥è¾“å‡ºå½¢çŠ¶
    assert high_level_logits.shape == (batch_size, config['num_agents'], 4), f"High level logits shape: {high_level_logits.shape}"
    assert low_level_logits.shape == (batch_size, config['num_agents'], config['action_dim']), f"Low level logits shape: {low_level_logits.shape}"
    assert value.shape == (batch_size, config['num_agents'], 1), f"Value shape: {value.shape}"
    
    print("âœ“ Model forward pass test passed!")
    return True

def test_ppo_action_selection():
    """æµ‹è¯•PPOåŠ¨ä½œé€‰æ‹©"""
    print("Testing PPO action selection...")
    
    config = get_config('small')
    
    # åˆ›å»ºæ¨¡å‹å’ŒPPO
    model = STHANModel(
        obs_dim=config['obs_dim'],
        action_dim=config['action_dim'],
        num_agents=config['num_agents'],
        history_len=config['history_len'],
        embed_dim=config['embed_dim'],
        n_heads=config['n_heads']
    )
    
    ppo = HierarchicalPPO(model, config)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 1
    obs = np.random.randn(batch_size, config['num_agents'], config['obs_dim'])
    neighbor_obs = np.random.randn(batch_size, config['num_agents'], config['num_neighbors'], config['obs_dim'])
    history_obs = np.random.randn(batch_size, config['num_agents'], config['history_len'], config['obs_dim'])
    
    # æµ‹è¯•è®­ç»ƒæ¨¡å¼
    high_level_actions, low_level_actions, high_level_log_probs, low_level_log_probs, value = \
        ppo.select_action(obs, neighbor_obs, history_obs, training=True)
    
    # æ£€æŸ¥è¾“å‡ºå½¢çŠ¶
    assert high_level_actions.shape == (batch_size, config['num_agents']), f"High level actions shape: {high_level_actions.shape}"
    assert low_level_actions.shape == (batch_size, config['num_agents']), f"Low level actions shape: {low_level_actions.shape}"
    assert high_level_log_probs.shape == (batch_size, config['num_agents']), f"High level log probs shape: {high_level_log_probs.shape}"
    assert low_level_log_probs.shape == (batch_size, config['num_agents']), f"Low level log probs shape: {low_level_log_probs.shape}"
    assert value.shape == (batch_size, config['num_agents'], 1), f"Value shape: {value.shape}"
    
    # æµ‹è¯•æ¨ç†æ¨¡å¼
    high_level_actions, low_level_actions, high_level_log_probs, low_level_log_probs, value = \
        ppo.select_action(obs, neighbor_obs, history_obs, training=False)
    
    print("âœ“ PPO action selection test passed!")
    return True

def test_utils():
    """æµ‹è¯•å·¥å…·å‡½æ•°"""
    print("Testing utility functions...")
    
    config = get_config('small')
    
    # æµ‹è¯•å†å²ç¼“å†²åŒº
    history_buffer = HistoryBuffer(
        max_len=config['history_len'],
        num_agents=config['num_agents'],
        obs_dim=config['obs_dim']
    )
    
    # æ·»åŠ ä¸€äº›è§‚æµ‹
    for i in range(5):
        obs = np.random.randn(config['num_agents'], config['obs_dim'])
        history_buffer.push(obs)
    
    history = history_buffer.get_history()
    assert history.shape == (config['num_agents'], config['history_len'], config['obs_dim']), f"History shape: {history.shape}"
    
    # æµ‹è¯•é‚»æ¥çŸ©é˜µåˆ›å»º
    adjacency_matrix = create_adjacency_matrix(config['num_agents'], 'grid')
    assert adjacency_matrix.shape == (config['num_agents'], config['num_agents']), f"Adjacency matrix shape: {adjacency_matrix.shape}"
    
    # æµ‹è¯•é‚»å±…è§‚æµ‹è·å–
    obs = np.random.randn(config['num_agents'], config['obs_dim'])
    neighbor_obs = get_neighbor_obs(obs, adjacency_matrix, config['num_neighbors'])
    assert neighbor_obs.shape == (config['num_agents'], config['num_neighbors'], config['obs_dim']), f"Neighbor obs shape: {neighbor_obs.shape}"
    
    # æµ‹è¯•ç‰¹å¾å¤„ç†
    processed_obs, processed_neighbor_obs, processed_history_obs = process_features(
        obs, neighbor_obs, history, config
    )
    
    # æµ‹è¯•å¥–åŠ±å¡‘å½¢
    raw_reward = np.random.randn(config['num_agents'])
    state = obs
    next_state = obs
    info = {
        'queue_length': np.random.randn(config['num_agents']),
        'waiting_time': np.random.randn(config['num_agents']),
        'throughput': np.random.randn(config['num_agents']),
        'pressure': np.random.randn(config['num_agents'])
    }
    
    shaped_reward = reward_shaping(raw_reward, state, next_state, info, config)
    assert shaped_reward.shape == raw_reward.shape, f"Shaped reward shape: {shaped_reward.shape}"
    
    # æµ‹è¯•äº¤é€šæŒ‡æ ‡è®¡ç®—
    metrics = compute_traffic_metrics(state, info)
    assert isinstance(metrics, dict), "Metrics should be a dictionary"
    
    print("âœ“ Utility functions test passed!")
    return True

def test_gae_computation():
    """æµ‹è¯•GAEè®¡ç®—"""
    print("Testing GAE computation...")
    
    config = get_config('small')
    ppo = HierarchicalPPO(None, config)  # ä¸éœ€è¦æ¨¡å‹æ¥æµ‹è¯•GAE
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    T = 10
    batch_size = 2
    num_agents = config['num_agents']
    
    rewards = torch.randn(T, batch_size, num_agents)
    values = torch.randn(T, batch_size, num_agents)
    dones = torch.randint(0, 2, (T, batch_size, num_agents)).float()
    next_value = torch.randn(batch_size, num_agents)
    
    # è®¡ç®—GAE
    advantages, returns = ppo.compute_gae(rewards, values, dones, next_value)
    
    # æ£€æŸ¥è¾“å‡ºå½¢çŠ¶
    assert advantages.shape == (T, batch_size, num_agents), f"Advantages shape: {advantages.shape}"
    assert returns.shape == (T, batch_size, num_agents), f"Returns shape: {returns.shape}"
    
    print("âœ“ GAE computation test passed!")
    return True

def test_config():
    """æµ‹è¯•é…ç½®ç³»ç»Ÿ"""
    print("Testing configuration system...")
    
    # æµ‹è¯•é»˜è®¤é…ç½®
    config = get_config('default')
    assert 'obs_dim' in config, "Default config should contain obs_dim"
    assert 'action_dim' in config, "Default config should contain action_dim"
    
    # æµ‹è¯•å°ç½‘ç»œé…ç½®
    small_config = get_config('small')
    assert small_config['num_agents'] == 4, f"Small config num_agents: {small_config['num_agents']}"
    assert small_config['embed_dim'] == 64, f"Small config embed_dim: {small_config['embed_dim']}"
    
    # æµ‹è¯•å¤§ç½‘ç»œé…ç½®
    large_config = get_config('large')
    assert large_config['num_agents'] == 16, f"Large config num_agents: {large_config['num_agents']}"
    assert large_config['embed_dim'] == 256, f"Large config embed_dim: {large_config['embed_dim']}"
    
    print("âœ“ Configuration system test passed!")
    return True

def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 50)
    print("Running STH Model Tests")
    print("=" * 50)
    
    tests = [
        test_config,
        test_model_forward,
        test_ppo_action_selection,
        test_utils,
        test_gae_computation,
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"âœ— {test.__name__} failed: {e}")
    
    print("=" * 50)
    print(f"Tests passed: {passed}/{total}")
    
    if passed == total:
        print("ğŸ‰ All tests passed! The STH model is ready to use.")
    else:
        print("âŒ Some tests failed. Please check the implementation.")
    
    return passed == total

if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1) 